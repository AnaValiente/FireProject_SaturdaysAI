{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases\n",
    "\n",
    "### Base cartogràfica d'incendis forestals - KMZ to CSV\n",
    "\n",
    "http://agricultura.gencat.cat/ca/serveis/cartografia-sig/bases-cartografiques/boscos/incendis-forestals/incendis-forestals-format-kmz/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import BytesIO,StringIO\n",
    "from zipfile import ZipFile\n",
    "import re,os\n",
    "import numpy as np\n",
    "import xml.sax, xml.sax.handler\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from html.parser import HTMLParser\n",
    "import glob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert KMZ files to CSV\n",
    "\n",
    "https://gist.github.com/linwoodc3/0306734dfe17076dfd34e09660c198c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversor code\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialize the base class\n",
    "        HTMLParser.__init__(self)\n",
    "        self.inTable=False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        self.series = pd.Series()\n",
    "        \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'table':\n",
    "            self.inTable = True\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.inTable:\n",
    "            self.buffer = data.strip(' \\n\\t').split(':')\n",
    "            if len(self.buffer)==2:\n",
    "                self.mapping[self.buffer[0]]=self.buffer[1]\n",
    "                self.series = pd.Series(self.mapping)\n",
    "        \n",
    "class PlacemarkHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.inName = False # handle XML parser events\n",
    "        self.inPlacemark = False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        \n",
    "    def startElement(self, name, attributes):\n",
    "        if name == \"Placemark\": # on start Placemark tag\n",
    "            self.inPlacemark = True\n",
    "            self.buffer = \"\" \n",
    "        if self.inPlacemark:\n",
    "            if name == \"name\": # on start title tag\n",
    "                self.inName = True # save name text to follow\n",
    "            \n",
    "    def characters(self, data):\n",
    "        if self.inPlacemark: # on text within tag\n",
    "            self.buffer += data # save text if in title\n",
    "            \n",
    "    def endElement(self, name):\n",
    "        self.buffer = self.buffer.strip('\\n\\t')\n",
    "        \n",
    "        if name == \"Placemark\":\n",
    "            self.inPlacemark = False\n",
    "            self.name_tag = \"\" #clear current name\n",
    "        \n",
    "        elif name == \"name\" and self.inPlacemark:\n",
    "            self.inName = False # on end title tag            \n",
    "            self.name_tag = self.buffer.strip()\n",
    "            self.mapping[self.name_tag] = {}\n",
    "        elif self.inPlacemark:\n",
    "            if name in self.mapping[self.name_tag]:\n",
    "                self.mapping[self.name_tag][name] += self.buffer\n",
    "            else:\n",
    "                self.mapping[self.name_tag][name] = self.buffer\n",
    "        self.buffer = \"\"\n",
    "        \n",
    "        \n",
    "    def spatializer(row):\n",
    "        \"\"\"\n",
    "        Function to convert string objects to Python spatial objects\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #############################\n",
    "        # coordinates field\n",
    "        #############################\n",
    "        try:\n",
    "            # look for the coordinates column\n",
    "            data = row['coordinates'].strip(' \\t\\n\\r')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        import ast\n",
    "        lsp = data.strip().split(' ')\n",
    "        linestring = map(lambda x: ast.literal_eval(x),lsp)\n",
    "        try:\n",
    "            spatial = Polygon(LineString(linestring))\n",
    "            convertedpoly = pd.Series({'geometry':spatial})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            try:\n",
    "                g = ast.literal_eval(data)\n",
    "                points = pd.Series({'geometry':Point(g[:2]),\n",
    "                                   'altitude':g[-1]})\n",
    "                return points\n",
    "            except:\n",
    "            \n",
    "                pass\n",
    "            \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Test for latitude and longitude columns\n",
    "            lat=float(row['latitude'])\n",
    "            lon=float(row['longitude'])\n",
    "            point = Point(lon,lat)\n",
    "            convertedpoly = pd.Series({'geometry':point})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    def htmlizer(row):\n",
    "        htmlparser = MyHTMLParser()\n",
    "        htmlparser.feed(row['description'])\n",
    "        return htmlparser.series\n",
    "        \n",
    "        \n",
    "def keyholemarkup2x(file,output='df'):\n",
    "    \"\"\"\n",
    "    Takes Keyhole Markup Language Zipped (KMZ) or KML file as input. The  \n",
    "    output is a pandas dataframe, geopandas geodataframe, csv, geojson, or\n",
    "    shapefile.\n",
    "    \n",
    "    All core functionality from:\n",
    "    http://programmingadvent.blogspot.com/2013/06/kmzkml-file-parsing-with-python.html\n",
    "    \n",
    "    Parameters\n",
    "        ----------\n",
    "        file : {string}\n",
    "            The string path to your KMZ or .\n",
    "        output : {string}\n",
    "            Defines the type of output. Valid selections include:\n",
    "                - shapefile - 'shp', 'shapefile', or 'ESRI Shapefile'\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "    \"\"\"\n",
    "    r = re.compile(r'(?<=\\.)km+[lz]?',re.I)\n",
    "    try:\n",
    "        extension = r.search(file).group(0) #(re.findall(r'(?<=\\.)[\\w]+',file))[-1]\n",
    "        \n",
    "    \n",
    "    except IOError as e:\n",
    "        logging.error(\"I/O error {0}\".format(e))\n",
    "    if (extension.lower()=='kml') is True:\n",
    "        buffer = file\n",
    "    elif (extension.lower()=='kmz') is True:\n",
    "        kmz = ZipFile(file, 'r')\n",
    "        \n",
    "        vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "        A = np.array(kmz.namelist())\n",
    "        sel = vmatch(A)\n",
    "        buffer = kmz.open(A[sel][0],'r')\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Incorrect file format entered.  Please provide the '\n",
    "                         'path to a valid KML or KMZ file.')    \n",
    "     \n",
    "    \n",
    "    parser = xml.sax.make_parser()\n",
    "    handler = PlacemarkHandler()\n",
    "    parser.setContentHandler(handler)\n",
    "    parser.parse(buffer)\n",
    "    \n",
    "    try:\n",
    "        kmz.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df = pd.DataFrame(handler.mapping).T\n",
    "    names = list(map(lambda x: x.lower(),df.columns))\n",
    "    if 'description' in names:\n",
    "        extradata = df.apply(PlacemarkHandler.htmlizer,axis=1)\n",
    "        df = df.join(extradata)\n",
    "    \n",
    "    \n",
    "    output = output.lower()\n",
    "    \n",
    "    if output=='df' or output=='dataframe' or output == None:\n",
    "        result = df\n",
    "        \n",
    "    elif output=='csv':\n",
    "        out_filename = file[:-3] + \"csv\"\n",
    "        df.to_csv(out_filename,encoding='utf-8',sep=\"\\t\")\n",
    "        result = (\"Successfully converted {0} to CSV and output to\"\n",
    "                   \" disk at {1}\".format(file,out_filename))\n",
    "        \n",
    "    elif output=='gpd' or output == 'gdf' or output=='geoframe' or output == 'geodataframe':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        result = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        \n",
    "        \n",
    "    elif output=='geojson' or output=='json':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "        try:\n",
    "            import geojson\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geojson. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"geojson\"\n",
    "        gdf.to_file(out_filename,driver='GeoJSON')\n",
    "        validation = geojson.is_valid(geojson.load(open(out_filename)))['valid']\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to GeoJSON and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The geojson conversion did not create a '\n",
    "                            'valid geojson object. Try to clean your '\n",
    "                            'data or try another file.')\n",
    "            \n",
    "    elif output=='shapefile' or output=='shp' or output =='esri shapefile':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import shapefile\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires pyshp. {0}'.format(e))\n",
    "        \n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"shp\"\n",
    "        gdf.to_file(out_filename,driver='ESRI Shapefile')\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        import shapefile\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        if len(sf.shapes())>0:\n",
    "            validation = \"yes\"\n",
    "        else:\n",
    "            validation = \"no\"\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to Shapefile and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The Shapefile conversion did not create a '\n",
    "                            'valid shapefile object. Try to clean your '\n",
    "                            'data or try another file.') \n",
    "    else:\n",
    "        raise ValueError('The conversion returned no data; check if'\n",
    "                        ' you entered a correct output file type. '\n",
    "                        'Valid output types are geojson, shapefile,'\n",
    "                        ' csv, geodataframe, and/or pandas dataframe.')\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-f2189c620ad4>:12: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  self.series = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "#Convert files\n",
    "\n",
    "#recover_dir = os.getcwd()\n",
    "#os.chdir(\".\\KMZ_files\")\n",
    "\n",
    "dict_incendis = {}\n",
    "\n",
    "#Columns to keep: Rowname  SimpleData coordinates\n",
    "#Files for 2017 and 2018 do NOT have SimpleData column (nor an equivalent one)\n",
    "\n",
    "for file in glob.glob(\"*.kmz\"):\n",
    "    file_name = file.split('.')[0]\n",
    "    curr_file = keyholemarkup2x(file)\n",
    "    if file_name == 'incendis17' or file_name == 'incendis18': \n",
    "        filt_file = curr_file[['coordinates']]\n",
    "        simpledata = ['NA'] * len(filt_file)\n",
    "        filt_file.insert(1, 'SimpleData', simpledata)\n",
    "    else: \n",
    "        filt_file = curr_file[['coordinates', 'SimpleData']]\n",
    "    dict_incendis[file_name] = filt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create single file\n",
    "\n",
    "complete_df = pd.DataFrame(columns = ['coordinates', 'SimpleData'])\n",
    "\n",
    "for i in dict_incendis:\n",
    "    complete_df = complete_df.append(dict_incendis[i])\n",
    "    \n",
    "len(complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>SimpleData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000080046</th>\n",
       "      <td>1.81781899249295,41.9324226292412,0 1.81933057...</td>\n",
       "      <td>2200008004620/02/00Viver i Serrateix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000080098</th>\n",
       "      <td>2.05223929623869,41.6901187011748,0 2.05103779...</td>\n",
       "      <td>2200008009807/04/00Sant Llorenç Savall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000080174</th>\n",
       "      <td>1.61459146008768,41.4154932795107,0 1.61309137...</td>\n",
       "      <td>2200008017414/07/00Torrelles de Foix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000080202</th>\n",
       "      <td>1.77775998993706,41.3137879343611,0 1.77895444...</td>\n",
       "      <td>2200008020229/07/00Olivella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000080203</th>\n",
       "      <td>1.76406403021004,41.3431411972265,0 1.76436703...</td>\n",
       "      <td>2200008020329/07/00Olèrdola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999430036</th>\n",
       "      <td>1.22567088702708,41.3198908121049,0 1.22567699...</td>\n",
       "      <td>222/02/99Valls1999430036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999430038</th>\n",
       "      <td>0.852718760975437,41.1215522042343,0 0.8521235...</td>\n",
       "      <td>222/02/99La Torre de Fontaubella1999430038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999430041</th>\n",
       "      <td>1.53193772698493,41.334758657397,0 1.531350480...</td>\n",
       "      <td>222/02/99El Montmell1999430041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999430061</th>\n",
       "      <td>1.19262992482761,41.3511095770843,0 1.19054523...</td>\n",
       "      <td>204/04/99Montblanc1999430061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999430122</th>\n",
       "      <td>0.503170693870319,40.945048737946,0 0.50257723...</td>\n",
       "      <td>206/11/99Benifallet1999430122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  coordinates  \\\n",
       "2000080046  1.81781899249295,41.9324226292412,0 1.81933057...   \n",
       "2000080098  2.05223929623869,41.6901187011748,0 2.05103779...   \n",
       "2000080174  1.61459146008768,41.4154932795107,0 1.61309137...   \n",
       "2000080202  1.77775998993706,41.3137879343611,0 1.77895444...   \n",
       "2000080203  1.76406403021004,41.3431411972265,0 1.76436703...   \n",
       "...                                                       ...   \n",
       "1999430036  1.22567088702708,41.3198908121049,0 1.22567699...   \n",
       "1999430038  0.852718760975437,41.1215522042343,0 0.8521235...   \n",
       "1999430041  1.53193772698493,41.334758657397,0 1.531350480...   \n",
       "1999430061  1.19262992482761,41.3511095770843,0 1.19054523...   \n",
       "1999430122  0.503170693870319,40.945048737946,0 0.50257723...   \n",
       "\n",
       "                                            SimpleData  \n",
       "2000080046        2200008004620/02/00Viver i Serrateix  \n",
       "2000080098      2200008009807/04/00Sant Llorenç Savall  \n",
       "2000080174        2200008017414/07/00Torrelles de Foix  \n",
       "2000080202                 2200008020229/07/00Olivella  \n",
       "2000080203                 2200008020329/07/00Olèrdola  \n",
       "...                                                ...  \n",
       "1999430036                    222/02/99Valls1999430036  \n",
       "1999430038  222/02/99La Torre de Fontaubella1999430038  \n",
       "1999430041              222/02/99El Montmell1999430041  \n",
       "1999430061                204/04/99Montblanc1999430061  \n",
       "1999430122               206/11/99Benifallet1999430122  \n",
       "\n",
       "[711 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
